#!/usr/bin/env python3
"""
Demo: Complete Workflow - Autonomous Data Agency v4.0

Este script demonstra o fluxo completo de trabalho da ag√™ncia:

1. Cliente faz uma solicita√ß√£o
2. PO analisa e cria requisitos
3. PM cria cronograma com depend√™ncias
4. ARQUITETURA define a solu√ß√£o (PRIMEIRO - decis√µes estrat√©gicas)
5. Times executam em paralelo quando poss√≠vel
6. QA valida cada entrega tecnicamente
7. PO valida se atende ao neg√≥cio
8. Ciclo continua at√© conclus√£o

Fluxo:
  Cliente ‚Üí PO ‚Üí PM ‚Üí ARQUITETURA ‚Üí [Data Eng | DevOps | Data Science] ‚Üí QA ‚Üí PO ‚Üí ‚úì
"""

import os
import sys
from datetime import datetime, timedelta
from typing import Dict, Any

# Adiciona o diret√≥rio raiz ao path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config.llm_config import get_llm, LLMProvider, LLM_CONFIGS
from core.pm_orchestrator import get_pm_orchestrator, ProjectPhase
from core.validation_workflow import get_validation_workflow
from core.team_communication import get_communication_hub
from core.hallucination_detector import get_hallucination_detector
from core.knowledge import get_knowledge_manager


def print_header(title: str, char: str = "="):
    """Imprime um cabe√ßalho formatado."""
    print(f"\n{char * 70}")
    print(f"  {title}")
    print(f"{char * 70}")


def print_phase(phase: str, description: str):
    """Imprime uma fase do workflow."""
    print(f"\n{'‚îÄ' * 70}")
    print(f"üìç FASE: {phase}")
    print(f"   {description}")
    print(f"{'‚îÄ' * 70}")


def print_team_action(team: str, action: str, details: str = ""):
    """Imprime uma a√ß√£o de um time."""
    icons = {
        "PO": "üìã",
        "PM": "üìä",
        "Architecture": "üèóÔ∏è",
        "Data Engineering": "‚öôÔ∏è",
        "DevOps": "üîß",
        "Data Science": "üß†",
        "QA": "üîç",
        "Client": "üë§"
    }
    icon = icons.get(team, "üìå")
    print(f"\n{icon} [{team}] {action}")
    if details:
        for line in details.split("\n"):
            print(f"   {line}")


def simulate_llm_response(prompt: str, agent_name: str, llm_provider: str) -> str:
    """Simula resposta de LLM (em produ√ß√£o, chamaria a API real)."""
    # Em produ√ß√£o, isso seria uma chamada real √† API do LLM
    responses = {
        "architecture": """
**Arquitetura Proposta: Sistema de An√°lise de Clientes**

1. **Cloud Provider:** AWS (melhor custo-benef√≠cio para o volume)
   - Alternativa: GCP se preferir BigQuery

2. **Componentes:**
   - Ingest√£o: Apache Airflow + Airbyte
   - Storage: S3 (raw) + Delta Lake (processed)
   - Processamento: Apache Spark on EMR Serverless
   - Serving: PostgreSQL (operacional) + Redis (cache)
   - ML: MLflow + SageMaker endpoints

3. **Estimativa de Custos:**
   - Desenvolvimento: ~$200/m√™s
   - Produ√ß√£o: ~$500-800/m√™s (dependendo do volume)

4. **Escalabilidade:**
   - Horizontal: Auto-scaling no EMR e ECS
   - Vertical: Upgrade de inst√¢ncias conforme necessidade

5. **Portabilidade:**
   - Containers Docker para todas as aplica√ß√µes
   - Terraform para IaC (facilita migra√ß√£o)
   - Formatos abertos (Parquet, Delta) evitam lock-in
""",
        "data_engineering": """
**Plano de Implementa√ß√£o: Data Pipelines**

1. **Ingest√£o:**
   - Conector SQL Server ‚Üí S3 (Airbyte)
   - Processamento de Excel ‚Üí Parquet (Python + Pandas)
   - Frequ√™ncia: Di√°ria (batch) com op√ß√£o de near-real-time

2. **Transforma√ß√µes:**
   - Bronze: Dados raw em Parquet
   - Silver: Dados limpos e validados
   - Gold: Modelos dimensionais para analytics

3. **Orquestra√ß√£o:**
   - Airflow DAGs para cada pipeline
   - Alertas via Slack/Email em caso de falha

4. **Qualidade de Dados:**
   - Great Expectations para valida√ß√µes
   - Testes de schema, completude, unicidade
""",
        "devops": """
**Plano de Infraestrutura**

1. **Provisionamento:**
   - Terraform modules para AWS
   - VPC com subnets p√∫blicas e privadas
   - Security groups restritivos

2. **CI/CD:**
   - GitHub Actions para pipelines
   - Ambientes: dev, staging, prod
   - Deploy automatizado com aprova√ß√£o manual para prod

3. **Monitoramento:**
   - CloudWatch para m√©tricas e logs
   - Grafana dashboards
   - PagerDuty para alertas cr√≠ticos
""",
        "qa": """
**Relat√≥rio de Valida√ß√£o QA**

‚úÖ Testes Unit√°rios: 47/47 passando
‚úÖ Testes de Integra√ß√£o: 12/12 passando
‚úÖ Testes de Data Quality: 8/8 passando
‚úÖ Cobertura de C√≥digo: 85%
‚úÖ Vulnerabilidades de Seguran√ßa: 0 cr√≠ticas, 2 baixas
‚úÖ Performance: Dentro dos limites (p99 < 500ms)

**Recomenda√ß√µes:**
- Resolver as 2 vulnerabilidades baixas antes do release
- Aumentar cobertura para 90% no pr√≥ximo sprint
""",
        "po": """
**Valida√ß√£o de Neg√≥cio**

‚úÖ Requisito 1: An√°lise de perfil de cliente - ATENDIDO
‚úÖ Requisito 2: Recomenda√ß√µes de produtos - ATENDIDO
‚úÖ Requisito 3: Integra√ß√£o WhatsApp - ATENDIDO
‚úÖ Requisito 4: Lembretes de anivers√°rio - ATENDIDO
‚úÖ Requisito 5: Previs√£o de pr√≥xima compra - ATENDIDO

**Feedback do Cliente:**
"O sistema atende √†s necessidades. Gostaria de adicionar 
an√°lise de sazonalidade no pr√≥ximo sprint."

**Decis√£o:** APROVADO para release
"""
    }
    return responses.get(agent_name.lower().replace(" ", "_"), f"Resposta simulada de {agent_name}")


def run_complete_workflow():
    """Executa o workflow completo da ag√™ncia."""
    
    print_header("AUTONOMOUS DATA AGENCY - WORKFLOW COMPLETO v4.0")
    print(f"\nüïê In√≠cio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Inicializa componentes
    pm = get_pm_orchestrator()
    workflow = get_validation_workflow()
    comm_hub = get_communication_hub()
    hallucination_detector = get_hallucination_detector()
    knowledge_manager = get_knowledge_manager()
    
    # =========================================================================
    # FASE 1: SOLICITA√á√ÉO DO CLIENTE
    # =========================================================================
    print_phase("1 - SOLICITA√á√ÉO DO CLIENTE", "Cliente apresenta sua necessidade")
    
    client_request = """
    Eu quero ter um bot de an√°lise de clientes para ter o perfil dele para saber 
    o que ele comprou, o que ele pode comprar mais, quando ele compra, qual ser√° 
    a pr√≥xima compra dele em estimativa, que produtos ele compra e quais ele 
    poderia comprar, lembretes de anivers√°rio e datas especiais para chamar o 
    cliente e para ter mais proximidade dele, e com tudo isso aumentar minhas 
    vendas e criar ou melhorar fidelidade do meu cliente.
    
    Fontes de dados: SQL Server e arquivos Excel
    Canal de comunica√ß√£o: WhatsApp e SMS
    """
    
    print_team_action("Client", "Apresenta solicita√ß√£o:", client_request.strip())
    
    # =========================================================================
    # FASE 2: AN√ÅLISE DO PO
    # =========================================================================
    print_phase("2 - AN√ÅLISE DO PO", "Product Owner analisa e estrutura requisitos")
    
    print_team_action("PO", "Analisa solicita√ß√£o e extrai requisitos")
    
    requirements = {
        "functional": [
            "An√°lise de perfil de cliente (hist√≥rico de compras)",
            "Sistema de recomenda√ß√£o de produtos relacionados",
            "Previs√£o de pr√≥xima compra (ML)",
            "Lembretes autom√°ticos (anivers√°rio, datas especiais)",
            "Integra√ß√£o com WhatsApp/SMS para comunica√ß√£o"
        ],
        "non_functional": [
            "LGPD compliance (dados pessoais criptografados)",
            "Disponibilidade 99.5%",
            "Lat√™ncia < 2s para recomenda√ß√µes",
            "Escal√°vel para 100k clientes"
        ],
        "data_sources": ["SQL Server", "Excel"],
        "has_ml": True,
        "has_streaming": False,
        "has_analytics": True,
        "data_volume": "medium",
        "team_size": 3
    }
    
    print_team_action("PO", "Requisitos estruturados:", f"""
Funcionais: {len(requirements['functional'])} requisitos
N√£o-funcionais: {len(requirements['non_functional'])} requisitos
Fontes de dados: {', '.join(requirements['data_sources'])}
Inclui ML: {'Sim' if requirements['has_ml'] else 'N√£o'}
""")
    
    # =========================================================================
    # FASE 3: PLANEJAMENTO DO PM
    # =========================================================================
    print_phase("3 - PLANEJAMENTO DO PM", "Project Manager cria cronograma e depend√™ncias")
    
    print_team_action("PM", "Cria projeto e gera cronograma")
    
    # Cria o projeto
    project = pm.create_project(
        project_id="proj_cliente_bot_001",
        project_name="Bot de An√°lise de Clientes",
        description="Sistema de an√°lise e recomenda√ß√£o para fideliza√ß√£o",
        client_requirements=client_request
    )
    
    # Gera cronograma
    execution_plan = pm.analyze_requirements_and_create_schedule(
        project_id="proj_cliente_bot_001",
        requirements=requirements
    )
    
    print_team_action("PM", "Cronograma gerado:", f"""
Total de tarefas: {execution_plan['total_tasks']}
Horas estimadas: {execution_plan['total_estimated_hours']}h
Dura√ß√£o estimada: {execution_plan['pm_analysis']['estimated_duration_weeks']} semanas
Checkpoints de valida√ß√£o: {execution_plan['pm_analysis']['validation_checkpoints']}
""")
    
    print("\nüìã Ordem de Execu√ß√£o (respeitando depend√™ncias):")
    for level in execution_plan["execution_levels"]:
        parallel = "‚ö° Paralelo" if level["can_parallelize"] else "‚Üí Sequencial"
        print(f"\n   N√≠vel {level['level']} ({parallel}):")
        for task in level["tasks"]:
            print(f"      [{task['assigned_team']:15}] {task['name']}")
    
    # =========================================================================
    # FASE 4: ARQUITETURA (CR√çTICO - SEMPRE PRIMEIRO)
    # =========================================================================
    print_phase("4 - ARQUITETURA", "Time de Arquitetura define a solu√ß√£o t√©cnica")
    
    print_team_action("Architecture", "Analisa requisitos e prop√µe arquitetura")
    
    # Busca conhecimento relevante
    arch_knowledge = knowledge_manager.get_knowledge_for_agent(
        domain="architecture",
        task="Definir arquitetura para sistema de an√°lise de clientes com ML",
        project_id="proj_cliente_bot_001"
    )
    
    # Simula resposta do time de arquitetura
    arch_response = simulate_llm_response("", "architecture", "gpt-4.1-mini")
    
    # Valida contra alucina√ß√µes
    validation = hallucination_detector.validate_response(
        response=arch_response,
        domain="architecture"
    )
    
    print_team_action("Architecture", "Proposta de Arquitetura:", arch_response.strip())
    
    print(f"\n   üõ°Ô∏è Valida√ß√£o Anti-Alucina√ß√£o:")
    print(f"      Score de Confian√ßa: {validation.overall_score:.1%}")
    print(f"      V√°lido: {'‚úÖ Sim' if validation.is_valid else '‚ùå N√£o'}")
    
    # Submete para valida√ß√£o
    arch_validation = workflow.submit_for_validation(
        task_id="task_arch_001",
        task_name="Defini√ß√£o de Arquitetura de Solu√ß√£o",
        task_type="architecture",
        assigned_team="architecture",
        deliverables=["Documento de Arquitetura", "Estimativa de Custos", "Diagrama"],
        original_requirements=requirements["functional"] + requirements["non_functional"],
        test_results={
            "all_tests_passed": True,
            "documentation_complete": True,
            "security_vulnerabilities": False
        }
    )
    
    # =========================================================================
    # FASE 5: EXECU√á√ÉO PARALELA (ap√≥s arquitetura aprovada)
    # =========================================================================
    print_phase("5 - EXECU√á√ÉO PARALELA", "Times executam tarefas em paralelo")
    
    # Registra comunica√ß√£o entre times
    comm_hub.register_team("architecture")
    comm_hub.register_team("data_engineering")
    comm_hub.register_team("devops")
    comm_hub.register_team("data_science")
    comm_hub.register_team("qa")
    
    comm_hub.handoff_task(
        from_team="architecture",
        to_team="data_engineering",
        task_description="Implementar pipelines conforme arquitetura aprovada",
        deliverables=["Pipelines ETL", "Testes", "Documenta√ß√£o"],
        context={"architecture_doc": "arch_v1.0", "priority": "high"}
    )
    
    comm_hub.handoff_task(
        from_team="architecture",
        to_team="devops",
        task_description="Provisionar infraestrutura AWS",
        deliverables=["Terraform", "Kubernetes", "Monitoring"],
        context={"architecture_doc": "arch_v1.0", "priority": "high"}
    )
    
    # Data Engineering
    print_team_action("Data Engineering", "Implementa pipelines de dados")
    de_response = simulate_llm_response("", "data_engineering", "gpt-4.1-nano")
    print(f"   {de_response[:200]}...")
    
    # DevOps (em paralelo)
    print_team_action("DevOps", "Provisiona infraestrutura")
    devops_response = simulate_llm_response("", "devops", "gemini-2.5-flash")
    print(f"   {devops_response[:200]}...")
    
    # Valida√ß√£o do QA para Data Engineering
    de_validation = workflow.submit_for_validation(
        task_id="task_de_001",
        task_name="Implementa√ß√£o de Data Pipelines",
        task_type="data_pipeline",
        assigned_team="data_engineering",
        deliverables=["Pipelines ETL", "Testes", "Documenta√ß√£o"],
        original_requirements=["Ingerir dados SQL Server", "Processar Excel", "Criar modelo dimensional"],
        test_results={
            "all_tests_passed": True,
            "data_quality_score": 0.95,
            "documentation_complete": True,
            "security_vulnerabilities": False
        }
    )
    
    # =========================================================================
    # FASE 6: DATA SCIENCE (ap√≥s pipelines prontos)
    # =========================================================================
    print_phase("6 - DATA SCIENCE", "Time de ML desenvolve modelos preditivos")
    
    print_team_action("Data Science", "Desenvolve modelo de recomenda√ß√£o e previs√£o")
    
    # Solicita ajuda do time de Data Engineering
    comm_hub.request_help(
        from_team="data_science",
        topic="Feature Engineering",
        description="Preciso de features agregadas de compras por cliente",
        required_expertise=["sql", "spark"]
    )
    
    print("""
   üìä Modelos desenvolvidos:
      1. Recomenda√ß√£o de produtos (Collaborative Filtering)
      2. Previs√£o de pr√≥xima compra (Time Series + XGBoost)
      3. Segmenta√ß√£o de clientes (K-Means)
   
   üìà M√©tricas:
      - Recomenda√ß√£o: Precision@10 = 0.78
      - Previs√£o: MAPE = 12%
      - Segmenta√ß√£o: Silhouette Score = 0.65
""")
    
    # =========================================================================
    # FASE 7: VALIDA√á√ÉO FINAL
    # =========================================================================
    print_phase("7 - VALIDA√á√ÉO FINAL", "QA e PO validam a solu√ß√£o completa")
    
    # QA Final
    print_team_action("QA", "Executa valida√ß√£o t√©cnica final")
    qa_response = simulate_llm_response("", "qa", "gpt-4.1-mini")
    print(qa_response)
    
    # PO Final
    print_team_action("PO", "Valida atendimento aos requisitos de neg√≥cio")
    po_response = simulate_llm_response("", "po", "gpt-4.1-mini")
    print(po_response)
    
    # =========================================================================
    # RESUMO FINAL
    # =========================================================================
    print_header("RESUMO DO PROJETO", "‚ïê")
    
    project_status = pm.get_project_status("proj_cliente_bot_001")
    workflow_summary = workflow.get_workflow_summary()
    comm_summary = comm_hub.get_all_team_statuses()
    
    print(f"""
üìã Projeto: {project['name']}
üìÖ Status: CONCLU√çDO

üìä M√©tricas de Execu√ß√£o:
   ‚Ä¢ Tarefas criadas: {execution_plan['total_tasks']}
   ‚Ä¢ Horas estimadas: {execution_plan['total_estimated_hours']}h
   ‚Ä¢ Dura√ß√£o: {execution_plan['pm_analysis']['estimated_duration_weeks']} semanas

‚úÖ Valida√ß√µes:
   ‚Ä¢ Total de submiss√µes: {workflow_summary['total_submissions']}
   ‚Ä¢ Aprovadas: {workflow_summary['approved']}
   ‚Ä¢ QA Score m√©dio: {workflow_summary['qa_summary'].get('average_quality_score', 0):.1%}
   ‚Ä¢ PO Score m√©dio: {workflow_summary['po_summary'].get('average_business_value', 0):.1%}

üì° Comunica√ß√£o entre Times:
   ‚Ä¢ Times registrados: {len(comm_summary)}
   ‚Ä¢ Handoffs realizados: 2
   ‚Ä¢ Colabora√ß√µes ativas: 1

üèóÔ∏è Arquitetura Final:
   ‚Ä¢ Cloud: AWS
   ‚Ä¢ Orquestra√ß√£o: Apache Airflow
   ‚Ä¢ Storage: S3 + Delta Lake
   ‚Ä¢ ML: MLflow + SageMaker
   ‚Ä¢ Custo estimado: $500-800/m√™s

üì± Entregas:
   ‚úì Pipeline de ingest√£o (SQL Server + Excel)
   ‚úì Modelo de recomenda√ß√£o de produtos
   ‚úì Previs√£o de pr√≥xima compra
   ‚úì Sistema de lembretes (anivers√°rio)
   ‚úì Integra√ß√£o WhatsApp/SMS
   ‚úì Dashboard de m√©tricas
""")
    
    print_header("FIM DA DEMONSTRA√á√ÉO", "‚ïê")
    print(f"\nüïê T√©rmino: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    run_complete_workflow()
